{"timestamp": 1234567890.123, "step": 1000, "loss": 2.345, "perplexity": 10.44, "sequences": [{"tokens": ["To", " be", " or", " not", " to", " be"], "predictions": [{"position": 0, "target_token_id": 5, "target_token_str": " be", "top_k": [{"token_id": 5, "token_str": " be", "prob": 0.6}, {"token_id": 12, "token_str": " live", "prob": 0.2}, {"token_id": 8, "token_str": " die", "prob": 0.1}, {"token_id": 20, "token_str": " exist", "prob": 0.05}, {"token_id": 15, "token_str": " sleep", "prob": 0.05}], "top_20": [{"token_id": 5, "token_str": " be", "prob": 0.6}, {"token_id": 12, "token_str": " live", "prob": 0.2}, {"token_id": 8, "token_str": " die", "prob": 0.1}, {"token_id": 20, "token_str": " exist", "prob": 0.05}, {"token_id": 15, "token_str": " sleep", "prob": 0.05}, {"token_id": 30, "token_str": " stay", "prob": 0.03}, {"token_id": 31, "token_str": " remain", "prob": 0.02}, {"token_id": 32, "token_str": " go", "prob": 0.01}, {"token_id": 33, "token_str": " come", "prob": 0.01}, {"token_id": 34, "token_str": " stand", "prob": 0.01}, {"token_id": 35, "token_str": " sit", "prob": 0.005}, {"token_id": 36, "token_str": " walk", "prob": 0.005}, {"token_id": 37, "token_str": " run", "prob": 0.003}, {"token_id": 38, "token_str": " think", "prob": 0.003}, {"token_id": 39, "token_str": " know", "prob": 0.002}, {"token_id": 40, "token_str": " see", "prob": 0.002}, {"token_id": 41, "token_str": " hear", "prob": 0.001}, {"token_id": 42, "token_str": " feel", "prob": 0.001}, {"token_id": 43, "token_str": " love", "prob": 0.001}, {"token_id": 44, "token_str": " hate", "prob": 0.001}], "entropy": 1.234}, {"position": 1, "target_token_id": 8, "target_token_str": " or", "top_k": [{"token_id": 8, "token_str": " or", "prob": 0.7}, {"token_id": 22, "token_str": ",", "prob": 0.15}, {"token_id": 23, "token_str": " and", "prob": 0.08}, {"token_id": 24, "token_str": ":", "prob": 0.04}, {"token_id": 25, "token_str": "?", "prob": 0.03}], "top_20": [{"token_id": 8, "token_str": " or", "prob": 0.7}, {"token_id": 22, "token_str": ",", "prob": 0.15}, {"token_id": 23, "token_str": " and", "prob": 0.08}, {"token_id": 24, "token_str": ":", "prob": 0.04}, {"token_id": 25, "token_str": "?", "prob": 0.03}], "entropy": 0.987}, {"position": 2, "target_token_id": 12, "target_token_str": " not", "top_k": [{"token_id": 12, "token_str": " not", "prob": 0.85}, {"token_id": 45, "token_str": " never", "prob": 0.08}, {"token_id": 46, "token_str": " ever", "prob": 0.04}, {"token_id": 47, "token_str": " always", "prob": 0.02}, {"token_id": 48, "token_str": " sometimes", "prob": 0.01}], "top_20": [{"token_id": 12, "token_str": " not", "prob": 0.85}, {"token_id": 45, "token_str": " never", "prob": 0.08}, {"token_id": 46, "token_str": " ever", "prob": 0.04}, {"token_id": 47, "token_str": " always", "prob": 0.02}, {"token_id": 48, "token_str": " sometimes", "prob": 0.01}], "entropy": 0.567}, {"position": 3, "target_token_id": 5, "target_token_str": " to", "top_k": [{"token_id": 5, "token_str": " to", "prob": 0.9}, {"token_id": 50, "token_str": " for", "prob": 0.05}, {"token_id": 51, "token_str": " with", "prob": 0.03}, {"token_id": 52, "token_str": " at", "prob": 0.01}, {"token_id": 53, "token_str": " in", "prob": 0.01}], "top_20": [{"token_id": 5, "token_str": " to", "prob": 0.9}, {"token_id": 50, "token_str": " for", "prob": 0.05}, {"token_id": 51, "token_str": " with", "prob": 0.03}, {"token_id": 52, "token_str": " at", "prob": 0.01}, {"token_id": 53, "token_str": " in", "prob": 0.01}], "entropy": 0.345}, {"position": 4, "target_token_id": 5, "target_token_str": " be", "top_k": [{"token_id": 5, "token_str": " be", "prob": 0.95}, {"token_id": 60, "token_str": " exist", "prob": 0.02}, {"token_id": 61, "token_str": " live", "prob": 0.02}, {"token_id": 62, "token_str": " die", "prob": 0.005}, {"token_id": 63, "token_str": " survive", "prob": 0.005}], "top_20": [{"token_id": 5, "token_str": " be", "prob": 0.95}, {"token_id": 60, "token_str": " exist", "prob": 0.02}, {"token_id": 61, "token_str": " live", "prob": 0.02}, {"token_id": 62, "token_str": " die", "prob": 0.005}, {"token_id": 63, "token_str": " survive", "prob": 0.005}], "entropy": 0.234}]}], "metadata": {"model_name": "meta-llama/Llama-3.2-1B", "vocab_size": 128256, "batch_size": 4, "sequence_length": 64}}
{"timestamp": 1234567891.123, "step": 1001, "loss": 2.234, "perplexity": 9.33, "sequences": [{"tokens": ["What", " is", " the", " question", "?"], "predictions": [{"position": 0, "target_token_id": 15, "target_token_str": " is", "top_k": [{"token_id": 15, "token_str": " is", "prob": 0.8}, {"token_id": 70, "token_str": " was", "prob": 0.1}, {"token_id": 71, "token_str": " are", "prob": 0.05}, {"token_id": 72, "token_str": " were", "prob": 0.03}, {"token_id": 73, "token_str": " be", "prob": 0.02}], "top_20": [{"token_id": 15, "token_str": " is", "prob": 0.8}, {"token_id": 70, "token_str": " was", "prob": 0.1}, {"token_id": 71, "token_str": " are", "prob": 0.05}, {"token_id": 72, "token_str": " were", "prob": 0.03}, {"token_id": 73, "token_str": " be", "prob": 0.02}], "entropy": 0.789}, {"position": 1, "target_token_id": 25, "target_token_str": " the", "top_k": [{"token_id": 25, "token_str": " the", "prob": 0.6}, {"token_id": 80, "token_str": " a", "prob": 0.2}, {"token_id": 81, "token_str": " this", "prob": 0.1}, {"token_id": 82, "token_str": " that", "prob": 0.05}, {"token_id": 83, "token_str": " our", "prob": 0.05}], "top_20": [{"token_id": 25, "token_str": " the", "prob": 0.6}, {"token_id": 80, "token_str": " a", "prob": 0.2}, {"token_id": 81, "token_str": " this", "prob": 0.1}, {"token_id": 82, "token_str": " that", "prob": 0.05}, {"token_id": 83, "token_str": " our", "prob": 0.05}], "entropy": 1.456}, {"position": 2, "target_token_id": 35, "target_token_str": " question", "top_k": [{"token_id": 35, "token_str": " question", "prob": 0.5}, {"token_id": 90, "token_str": " answer", "prob": 0.25}, {"token_id": 91, "token_str": " problem", "prob": 0.15}, {"token_id": 92, "token_str": " matter", "prob": 0.05}, {"token_id": 93, "token_str": " issue", "prob": 0.05}], "top_20": [{"token_id": 35, "token_str": " question", "prob": 0.5}, {"token_id": 90, "token_str": " answer", "prob": 0.25}, {"token_id": 91, "token_str": " problem", "prob": 0.15}, {"token_id": 92, "token_str": " matter", "prob": 0.05}, {"token_id": 93, "token_str": " issue", "prob": 0.05}], "entropy": 1.789}, {"position": 3, "target_token_id": 45, "target_token_str": "?", "top_k": [{"token_id": 45, "token_str": "?", "prob": 0.9}, {"token_id": 100, "token_str": ".", "prob": 0.05}, {"token_id": 101, "token_str": "!", "prob": 0.03}, {"token_id": 102, "token_str": "...", "prob": 0.01}, {"token_id": 103, "token_str": ";", "prob": 0.01}], "top_20": [{"token_id": 45, "token_str": "?", "prob": 0.9}, {"token_id": 100, "token_str": ".", "prob": 0.05}, {"token_id": 101, "token_str": "!", "prob": 0.03}, {"token_id": 102, "token_str": "...", "prob": 0.01}, {"token_id": 103, "token_str": ";", "prob": 0.01}], "entropy": 0.456}]}], "metadata": {"model_name": "meta-llama/Llama-3.2-1B", "vocab_size": 128256, "batch_size": 4, "sequence_length": 64}}
{"timestamp": 1234567892.123, "step": 1002, "loss": 2.123, "perplexity": 8.36, "sequences": [{"tokens": ["Romeo", ",", " Romeo", ",", " wherefore", " art", " thou"], "predictions": [{"position": 0, "target_token_id": 110, "target_token_str": ",", "top_k": [{"token_id": 110, "token_str": ",", "prob": 0.7}, {"token_id": 111, "token_str": "!", "prob": 0.15}, {"token_id": 112, "token_str": ".", "prob": 0.1}, {"token_id": 113, "token_str": ":", "prob": 0.03}, {"token_id": 114, "token_str": "?", "prob": 0.02}], "top_20": [{"token_id": 110, "token_str": ",", "prob": 0.7}, {"token_id": 111, "token_str": "!", "prob": 0.15}, {"token_id": 112, "token_str": ".", "prob": 0.1}, {"token_id": 113, "token_str": ":", "prob": 0.03}, {"token_id": 114, "token_str": "?", "prob": 0.02}], "entropy": 0.987}, {"position": 1, "target_token_id": 120, "target_token_str": " Romeo", "top_k": [{"token_id": 120, "token_str": " Romeo", "prob": 0.85}, {"token_id": 121, "token_str": " my", "prob": 0.08}, {"token_id": 122, "token_str": " oh", "prob": 0.04}, {"token_id": 123, "token_str": " dear", "prob": 0.02}, {"token_id": 124, "token_str": " sweet", "prob": 0.01}], "top_20": [{"token_id": 120, "token_str": " Romeo", "prob": 0.85}, {"token_id": 121, "token_str": " my", "prob": 0.08}, {"token_id": 122, "token_str": " oh", "prob": 0.04}, {"token_id": 123, "token_str": " dear", "prob": 0.02}, {"token_id": 124, "token_str": " sweet", "prob": 0.01}], "entropy": 0.654}, {"position": 2, "target_token_id": 110, "target_token_str": ",", "top_k": [{"token_id": 110, "token_str": ",", "prob": 0.95}, {"token_id": 130, "token_str": "!", "prob": 0.03}, {"token_id": 131, "token_str": "?", "prob": 0.01}, {"token_id": 132, "token_str": ".", "prob": 0.005}, {"token_id": 133, "token_str": "...", "prob": 0.005}], "top_20": [{"token_id": 110, "token_str": ",", "prob": 0.95}, {"token_id": 130, "token_str": "!", "prob": 0.03}, {"token_id": 131, "token_str": "?", "prob": 0.01}, {"token_id": 132, "token_str": ".", "prob": 0.005}, {"token_id": 133, "token_str": "...", "prob": 0.005}], "entropy": 0.234}, {"position": 3, "target_token_id": 140, "target_token_str": " wherefore", "top_k": [{"token_id": 140, "token_str": " wherefore", "prob": 0.6}, {"token_id": 141, "token_str": " why", "prob": 0.2}, {"token_id": 142, "token_str": " where", "prob": 0.1}, {"token_id": 143, "token_str": " what", "prob": 0.05}, {"token_id": 144, "token_str": " how", "prob": 0.05}], "top_20": [{"token_id": 140, "token_str": " wherefore", "prob": 0.6}, {"token_id": 141, "token_str": " why", "prob": 0.2}, {"token_id": 142, "token_str": " where", "prob": 0.1}, {"token_id": 143, "token_str": " what", "prob": 0.05}, {"token_id": 144, "token_str": " how", "prob": 0.05}], "entropy": 1.345}, {"position": 4, "target_token_id": 150, "target_token_str": " art", "top_k": [{"token_id": 150, "token_str": " art", "prob": 0.75}, {"token_id": 151, "token_str": " are", "prob": 0.15}, {"token_id": 152, "token_str": " is", "prob": 0.05}, {"token_id": 153, "token_str": " be", "prob": 0.03}, {"token_id": 154, "token_str": " were", "prob": 0.02}], "top_20": [{"token_id": 150, "token_str": " art", "prob": 0.75}, {"token_id": 151, "token_str": " are", "prob": 0.15}, {"token_id": 152, "token_str": " is", "prob": 0.05}, {"token_id": 153, "token_str": " be", "prob": 0.03}, {"token_id": 154, "token_str": " were", "prob": 0.02}], "entropy": 0.876}, {"position": 5, "target_token_id": 160, "target_token_str": " thou", "top_k": [{"token_id": 160, "token_str": " thou", "prob": 0.9}, {"token_id": 161, "token_str": " you", "prob": 0.06}, {"token_id": 162, "token_str": " thee", "prob": 0.02}, {"token_id": 163, "token_str": " thy", "prob": 0.01}, {"token_id": 164, "token_str": " ye", "prob": 0.01}], "top_20": [{"token_id": 160, "token_str": " thou", "prob": 0.9}, {"token_id": 161, "token_str": " you", "prob": 0.06}, {"token_id": 162, "token_str": " thee", "prob": 0.02}, {"token_id": 163, "token_str": " thy", "prob": 0.01}, {"token_id": 164, "token_str": " ye", "prob": 0.01}], "entropy": 0.432}]}], "metadata": {"model_name": "meta-llama/Llama-3.2-1B", "vocab_size": 128256, "batch_size": 4, "sequence_length": 64}}